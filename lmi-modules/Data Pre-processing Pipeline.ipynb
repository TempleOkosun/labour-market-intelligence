{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labour Market Intelligence Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.1.2 Data Pre-processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module Objective:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module will handle pre-processing of data in order to get data into the right form for analysis. The following operations will be performed:\n",
    "\n",
    "1. Load data downloaded by the Scraping Module.\n",
    "2. If more data exist, then load as well and merge.\n",
    "3. Clean the data.\n",
    "4. Integrate missing data\n",
    "5. De-duplicate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisite: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A thorough understanding of the data.\n",
    "2. Data has been scraped from job portals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input:\n",
    "Scraped Job Ads in either JSON data format or in a MongoDB Collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output:\n",
    "Cleaned data in JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk # Tkinter is used so that file import/export is simplified and chances of errors minimized. \n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader():\n",
    "    \n",
    "    def greet():\n",
    "        welcome_msg = ('Welcome to the Data Pre-processor of the LMI System. '+\n",
    "                       'We will begin by loading the data sets into memory.')        \n",
    "        print(welcome_msg)\n",
    "    \n",
    "    \n",
    "    greet() \n",
    "    time.sleep(0.20) # Jupyter Notebook Print-vs-Input Workaround. \n",
    "                 # This will prevent the input statement below from executing before the print. \n",
    "                # https://stackoverflow.com/questions/50439035/jupyter-notebook-input-line-executed-before-print-statement\n",
    "    \n",
    "    \n",
    "    main_menu_msg = ('\\nPlease select an option [1, 2 or 0 to exit]: '+\n",
    "                     '\\n [1] To Import JSON data format.'+                     \n",
    "                     '\\n [2] To Import from MongoDB.'+\n",
    "                     '\\n [0] To Exit.'+\n",
    "                     '\\n ')        \n",
    "    try:\n",
    "        main_menu_option = int(input(main_menu_msg)) \n",
    "        if (main_menu_option==1):\n",
    "            \n",
    "            # Define a function-L1\n",
    "            def json_file_handler():\n",
    "                msg = '\\nLoad JSON Documents.'\n",
    "                print(msg)\n",
    "                time.sleep(0.20) # Jupyter Notebook Print-vs-Input Workaround. \n",
    "                    # This will prevent the input statement below from executing before the print. \n",
    "                # https://stackoverflow.com/questions/50439035/jupyter-notebook-input-line-executed-before-print-statement\n",
    "\n",
    "                # A sub function-L2\n",
    "                def json_file_path():\n",
    "                    input('Press Enter to browse to the file location.') # Any key works.Pause to ensure user is in control.                                                                 \n",
    "                    root = tk.Tk()                             \n",
    "                    root.withdraw() # Hides the root frame. Else, a frame will be hanging around & closing it will cause a crash\n",
    "                    root.update()  # may be necessary to force the hiding of the main frame.\n",
    "                    file_name = askopenfilename()             \n",
    "                    root.destroy()  \n",
    "                    return file_name\n",
    "                \n",
    "                json_file_name = json_file_path()\n",
    "                print('The selected file is: ' + json_file_name)     \n",
    "\n",
    "\n",
    "                json_structure_msg =('\\nPlease select an option [1 or 2]'+\n",
    "                    ' to indicate how JSON Objects were organized in the file:\\n'+\n",
    "                    '  [1] An array of JSON objects seperated by a comma \\',\\' as shown below:\\n'+\n",
    "                    '    [{\"Job_Id\":\"15\",\"Location\":\"Aberdeen\"}, {\"Job_Id\":\"67\",\"Location\":\"Dundee\"}] \\n\\n'+\n",
    "                    '  [2] One JSON object per line usually when JSON was exported from MongoDB as shown below:\\n'+\n",
    "                    '    NB- Anything within {} is treated as a single line even if the text spans multiple lines.\\n'+\n",
    "                    '    {\"Job_Id\":\"11\",\"Location\":\"Cork\"}\\n'+\n",
    "                    '    {\"Job_Id\":\"30\",\"Location\":\"England\"}\\n')\n",
    "\n",
    "                json_structure_option = int(input(json_structure_msg))\n",
    "                if (json_structure_option==1):\n",
    "                    df = pd.read_json(path_or_buf=json_file_name, lines=False) \n",
    "                    print (json_file_name)\n",
    "                    print(df.info()) \n",
    "\n",
    "                elif(json_structure_option==2):\n",
    "                    df = pd.read_json(path_or_buf=json_file_name, lines=True)    \n",
    "                    print (json_file_name)\n",
    "                    print(df.info()) \n",
    "\n",
    "                else:\n",
    "                    print('Invalid Input')              \n",
    "                                          \n",
    "                    \n",
    "            def merge_data():                    \n",
    "                    merge_data_option=1\n",
    "                    while (merge_data_option==1):                        \n",
    "                        merge_data_msg = ('\\nWould you like to add i.e. merge another data to the loaded data.'+\n",
    "                               '\\nPlease select an option [1 or 2]\\n'+\n",
    "                               '  [1] Yes to add \\n'+\n",
    "                               '  [2] No to proceed with data preparation.')\n",
    "                        merge_data_option = int(input(merge_data_msg))\n",
    "                        if (merge_data_option==1):\n",
    "                            currentpath = json_file_path()\n",
    "                            print (currentpath)\n",
    "\n",
    "                        elif(json_structure_option==2):\n",
    "                            df = pd.read_json(path_or_buf=json_file_name, lines=True)    \n",
    "                            print (json_file_name)\n",
    "                            print(df.info()) \n",
    "\n",
    "                        else:\n",
    "                            print('Invalid Input')\n",
    "            # Use the function\n",
    "            json_file_handler()\n",
    "            merge_data()\n",
    "                \n",
    "    except ValueError:\n",
    "            print('Input Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Data Pre-processor of the LMI System. We will begin by loading the data sets into memory.\n",
      "\n",
      "Please select an option [1, 2 or 0 to exit]: \n",
      " [1] To Import JSON data format.\n",
      " [2] To Import from MongoDB.\n",
      " [0] To Exit.\n",
      " 1\n",
      "\n",
      "Load JSON Documents.\n",
      "Press Enter to browse to the file location.\n",
      "The selected file is: C:/Users/User/Desktop/Test Files/TestJson1.json\n",
      "\n",
      "Please select an option [1 or 2] to indicate how JSON Objects were organized in the file:\n",
      "  [1] An array of JSON objects seperated by a comma ',' as shown below:\n",
      "    [{\"Job_Id\":\"15\",\"Location\":\"Aberdeen\"}, {\"Job_Id\":\"67\",\"Location\":\"Dundee\"}] \n",
      "\n",
      "  [2] One JSON object per line usually when JSON was exported from MongoDB as shown below:\n",
      "    NB- Anything within {} is treated as a single line even if the text spans multiple lines.\n",
      "    {\"Job_Id\":\"11\",\"Location\":\"Cork\"}\n",
      "    {\"Job_Id\":\"30\",\"Location\":\"England\"}\n",
      "2\n",
      "C:/Users/User/Desktop/Test Files/TestJson1.json\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10101 entries, 0 to 10100\n",
      "Data columns (total 17 columns):\n",
      "Country            10101 non-null object\n",
      "Data_Source        10101 non-null object\n",
      "Date_Posted        10101 non-null object\n",
      "Industry           10101 non-null object\n",
      "Job_Description    10101 non-null object\n",
      "Job_Id             10101 non-null int64\n",
      "Job_Poster_Url     10101 non-null object\n",
      "Job_Title          10027 non-null object\n",
      "Job_Type           10101 non-null object\n",
      "Job_Url            10101 non-null object\n",
      "Location           10101 non-null object\n",
      "Posted_By          10101 non-null object\n",
      "Region             10101 non-null object\n",
      "Salary             10101 non-null object\n",
      "Time_Crawled       10101 non-null object\n",
      "Valid_Till         10101 non-null object\n",
      "_id                10101 non-null object\n",
      "dtypes: int64(1), object(16)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "\n",
      "Would you like to add i.e. merge another data to the loaded data.\n",
      "Please select an option [1 or 2]\n",
      "  [1] Yes to add \n",
      "  [2] No to proceed with data preparation.1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json_file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-cfdc9a0ad2fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-d089483ef6ae>\u001b[0m in \u001b[0;36mdata_loader\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;31m# Use the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mjson_file_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0mmerge_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-d089483ef6ae>\u001b[0m in \u001b[0;36mmerge_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m                         \u001b[0mmerge_data_option\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_data_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmerge_data_option\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                             \u001b[0mcurrentpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_file_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m                             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcurrentpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json_file_path' is not defined"
     ]
    }
   ],
   "source": [
    "data_loader()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
